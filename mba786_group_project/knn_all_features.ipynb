{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d78d990-72ea-4548-9efe-417eba89e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (1.14.0)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from scipy) (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.52.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\shory\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb11405-6016-43cb-8d40-ef895fc11c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc07e843-594a-4e71-90d6-38a5cf7036d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('credit.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a47695-bbcf-4ed2-a9ac-b4d07b9791cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'Class' to binary\n",
    "data['Class_code'] = data['Class'].map({'Good': 0, 'Bad': 1})  # 0 for Good, 1 for Bad\n",
    "\n",
    "# Prepare the features and target\n",
    "features = data.drop(columns=['Class', 'Class_code'])\n",
    "target = data['Class_code']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "y = target\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a range of k values to test\n",
    "k_values = [1,3,5,10]  # Testing k from 1 to 20\n",
    "p_values =[.5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "087568ae-d035-47ea-bd45-13cd51a275f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2339528435.py, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 51\u001b[1;36m\u001b[0m\n\u001b[1;33m    def calculate_metrics(conf_matrix):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Store results for each k\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "results = []\n",
    "\n",
    "for k in k_values:\n",
    "    for prob_threshold in p_values:\n",
    "    # k-Nearest Neighbors model\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions with k-NN\n",
    "        y_prob = knn_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Use a fixed threshold for binary classification\n",
    "       \n",
    "        y_pred = (y_prob >= prob_threshold).astype(int)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Calculate confusion matrix and ROC AUC\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f\"Confusion matrix with k equals {k:.0f} and threshold equals {prob_threshold:.2f} \")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "  #To calculate the TPR and FPR\n",
    "        TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "  # Calculating TPR and FPR\n",
    "        TPR = TP / (TP + FN)\n",
    "        FPR = FP / (FP + TN)\n",
    "\n",
    "  # Display the results\n",
    "   \n",
    "\n",
    "    # Plotting the confusion matrix\n",
    "  \n",
    "    \n",
    "    # Collecting results\n",
    "        results.append({\n",
    "            'k': k,\n",
    "            'Accuracy': accuracy,\n",
    "            'AUC': auc\n",
    "            def calculate_metrics(conf_matrix):\n",
    "            \n",
    "            TN, FP, FN, TP = conf_matrix.ravel()\n",
    "            TPR = TP / (TP + FN)  # True Positive Rate (Recall)\n",
    "            FPR = FP / (FP + TN)  # False Positive Rate\n",
    "            Precision = TP / (TP + FP) if (TP + FP) != 0 else 0  # Precision\n",
    "            Accuracy = (TP + TN) / (TP + TN + FP + FN)  # Accuracy\n",
    "            Recall = TPR  # Recall is the same as TPR\n",
    "            return {'Accuracy': Accuracy, 'Precision': Precision, 'Recall': Recall, 'FPR': FPR, 'TPR': TPR}\n",
    "\n",
    "            print(metrics_df)\n",
    "            # Function to calculate evaluation metrics\n",
    "\n",
    "         })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d361f57-1fbc-4132-8126-b2f406d2763c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0382406-05c3-4e37-90bc-6345e917ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results_df['k'], results_df['Accuracy'], marker='o', label='Accuracy')\n",
    "plt.plot(results_df['k'], results_df['AUC'], marker='o', label='AUC')\n",
    "plt.xticks(k_values)\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Performance Metric')\n",
    "plt.title('k-NN Performance Metrics for Different k Values')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e8ee7-c916-43a1-af8f-aa17a3549338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Assuming results is a list of dictionaries with 'k', 'prob_threshold', 'Accuracy', and 'AUC'\n",
    "# results = [{'k': k, 'prob_threshold': pt, 'Accuracy': acc, 'AUC': auc}, ...]\n",
    "\n",
    "# Extract data for plotting\n",
    "ks = np.array([result['k'] for result in results])\n",
    "prob_thresholds = np.array([p_values])\n",
    "accuracies = np.array([result['Accuracy'] for result in results])\n",
    "aucs = np.array([result['AUC'] for result in results])\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plotting Accuracy\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.scatter(ks, prob_threshold, accuracies, c=accuracies, cmap='viridis')\n",
    "ax1.set_xlabel('Number of Neighbors (k)')\n",
    "ax1.set_ylabel('Probability Threshold')\n",
    "ax1.set_zlabel('Accuracy')\n",
    "ax1.set_title('Accuracy vs k and Probability Threshold')\n",
    "\n",
    "# Plotting AUC\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.scatter(ks, prob_thresholds, aucs, c=aucs, cmap='viridis')\n",
    "ax2.set_xlabel('Number of Neighbors (k)')\n",
    "ax2.set_ylabel('Probability Threshold')\n",
    "ax2.set_zlabel('AUC')\n",
    "ax2.set_title('AUC vs k and Probability Threshold')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9f067-2815-43f2-958c-d2bdbf41b039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
